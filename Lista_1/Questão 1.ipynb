{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução Primeira Lista de Exercícios\n",
    "<ul>\n",
    "    <li>Universidade Federal da Paraíba</li>\n",
    "    <li>Tópicos Especiais em Computação Deep Learning</li>\n",
    "    <li>Professor: Tiago Maritan</li>\n",
    "    <li>Aluno: Matheus de Araújo Correia Lima Melo</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"O problema pode ser formulado como um classificador de 8 padrões diferentes, sendo que cada padrão representa um vértice do cubo.\"\n",
    "##### Sendo\n",
    "<ul>\n",
    "    <li>Padrão 1: x={0,0,0} com  vetor resposta d={ 1, 0, 0, 0, 0, 0, 0, 0}</li>\n",
    "    <li>Padrão 2: x={0,0,1} com  vetor resposta d={ 0, 1, 0, 0, 0, 0, 0, 0}</li>\n",
    "    <li>Padrão 3: x={0,1,0} com  vetor resposta d={ 0, 0, 1, 0, 0, 0, 0, 0}</li>\n",
    "    <li>Padrão 4: x={0,1,1} com  vetor resposta d={ 0, 0, 0, 1, 0, 0, 0, 0}</li>\n",
    "    <li>Padrão 5: x={1,0,0} com  vetor resposta d={ 0, 0, 0, 0, 1, 0, 0, 0}</li>\n",
    "    <li>Padrão 6: x={1,0,1} com  vetor resposta d={ 0, 0, 0, 0, 0, 1, 0, 0}</li>\n",
    "    <li>Padrão 7: x={1,1,0} com  vetor resposta d={ 0, 0, 0, 0, 0, 0, 1, 0}</li>\n",
    "    <li>Padrão 8: x={1,1,1} com  vetor resposta d={ 0, 0, 0, 0, 0, 0, 0, 1}</li>    \n",
    "</ul>\n",
    "Devem ser considerados ruídos com raio de no máx 0.1, de forma que, se presentes, ainda sejam classificados corretamente.\n",
    "Para tanto constrói-se a seguir um conjunto de 4000 exemplos de dados rótulados(500 para cada rótulo) para o problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_1 = [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "vector_2 = [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "vector_3 = [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "vector_4 = [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "vector_5 = [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "vector_6 = [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "vector_7 = [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "vector_8 = [0, 0, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    #Padrão 1 x= 0,0,0 -> Vetor Resposta 1\n",
    "    random_1 = [0 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_1)\n",
    "    train_labels.append(vector_1)\n",
    "    \n",
    "    #Padrão 2 x= 0,0,1 -> Vetor Resposta 2\n",
    "    random_2 = [0 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_2)\n",
    "    train_labels.append(vector_2)\n",
    "    \n",
    "    #Padrão 3 x= 0,1,0 -> Vetor Resposta 3\n",
    "    random_3 = [0 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_3)\n",
    "    train_labels.append(vector_3)\n",
    "    \n",
    "    #Padrão 4 x= 0,1,1 -> Vetor Resposta 4\n",
    "    random_4 = [0 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_4)\n",
    "    train_labels.append(vector_4)\n",
    "    \n",
    "    #Padrão 5 x= 1,0,0 -> Vetor Resposta 5\n",
    "    random_5 = [1 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_5)\n",
    "    train_labels.append(vector_5)\n",
    "    \n",
    "    #Padrão 6 x= 1,0,1 -> Vetor Resposta 6\n",
    "    random_6 = [1 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_6)\n",
    "    train_labels.append(vector_6)\n",
    "    \n",
    "    #Padrão 7 x= 1,1,0 -> Vetor Resposta 7\n",
    "    random_7 = [1 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1, 0 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_7)\n",
    "    train_labels.append(vector_7)\n",
    "    \n",
    "    #Padrão 8 x= 1,1,1 -> Vetor Resposta 8\n",
    "    random_8 = [1 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1, 1 + uniform(-1,1)*0.1]\n",
    "    train_samples.append(random_8)\n",
    "    train_labels.append(vector_8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar os dados em numpy arrays para inserir na fit function\n",
    "#Fazer o shuffle para evitar que a rede aprenda a ordem\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.activations import hard_sigmoid\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=8, input_shape=(3,), activation=hard_sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 8)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "7/7 - 0s - loss: 2.0619 - accuracy: 0.1719 - val_loss: 2.0647 - val_accuracy: 0.0625\n",
      "Epoch 2/28\n",
      "7/7 - 0s - loss: 2.0301 - accuracy: 0.1719 - val_loss: 2.0344 - val_accuracy: 0.0625\n",
      "Epoch 3/28\n",
      "7/7 - 0s - loss: 2.0011 - accuracy: 0.1406 - val_loss: 2.0054 - val_accuracy: 0.0625\n",
      "Epoch 4/28\n",
      "7/7 - 0s - loss: 1.9727 - accuracy: 0.1562 - val_loss: 1.9773 - val_accuracy: 0.1875\n",
      "Epoch 5/28\n",
      "7/7 - 0s - loss: 1.9439 - accuracy: 0.2031 - val_loss: 1.9517 - val_accuracy: 0.1875\n",
      "Epoch 6/28\n",
      "7/7 - 0s - loss: 1.9146 - accuracy: 0.2969 - val_loss: 1.9232 - val_accuracy: 0.1875\n",
      "Epoch 7/28\n",
      "7/7 - 0s - loss: 1.8853 - accuracy: 0.3281 - val_loss: 1.8940 - val_accuracy: 0.1875\n",
      "Epoch 8/28\n",
      "7/7 - 0s - loss: 1.8567 - accuracy: 0.3438 - val_loss: 1.8674 - val_accuracy: 0.1875\n",
      "Epoch 9/28\n",
      "7/7 - 0s - loss: 1.8249 - accuracy: 0.3594 - val_loss: 1.8387 - val_accuracy: 0.2500\n",
      "Epoch 10/28\n",
      "7/7 - 0s - loss: 1.7952 - accuracy: 0.4062 - val_loss: 1.8110 - val_accuracy: 0.2500\n",
      "Epoch 11/28\n",
      "7/7 - 0s - loss: 1.7647 - accuracy: 0.4531 - val_loss: 1.7821 - val_accuracy: 0.3750\n",
      "Epoch 12/28\n",
      "7/7 - 0s - loss: 1.7347 - accuracy: 0.5156 - val_loss: 1.7507 - val_accuracy: 0.3750\n",
      "Epoch 13/28\n",
      "7/7 - 0s - loss: 1.7024 - accuracy: 0.5156 - val_loss: 1.7178 - val_accuracy: 0.3750\n",
      "Epoch 14/28\n",
      "7/7 - 0s - loss: 1.6692 - accuracy: 0.5156 - val_loss: 1.6865 - val_accuracy: 0.3750\n",
      "Epoch 15/28\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.5312 - val_loss: 1.6507 - val_accuracy: 0.3750\n",
      "Epoch 16/28\n",
      "7/7 - 0s - loss: 1.5969 - accuracy: 0.5312 - val_loss: 1.6104 - val_accuracy: 0.3750\n",
      "Epoch 17/28\n",
      "7/7 - 0s - loss: 1.5600 - accuracy: 0.5312 - val_loss: 1.5691 - val_accuracy: 0.3750\n",
      "Epoch 18/28\n",
      "7/7 - 0s - loss: 1.5194 - accuracy: 0.5312 - val_loss: 1.5263 - val_accuracy: 0.3750\n",
      "Epoch 19/28\n",
      "7/7 - 0s - loss: 1.4781 - accuracy: 0.5469 - val_loss: 1.4870 - val_accuracy: 0.4375\n",
      "Epoch 20/28\n",
      "7/7 - 0s - loss: 1.4385 - accuracy: 0.5625 - val_loss: 1.4507 - val_accuracy: 0.6250\n",
      "Epoch 21/28\n",
      "7/7 - 0s - loss: 1.3970 - accuracy: 0.5938 - val_loss: 1.4124 - val_accuracy: 0.6250\n",
      "Epoch 22/28\n",
      "7/7 - 0s - loss: 1.3516 - accuracy: 0.6250 - val_loss: 1.3701 - val_accuracy: 0.6250\n",
      "Epoch 23/28\n",
      "7/7 - 0s - loss: 1.3030 - accuracy: 0.7500 - val_loss: 1.3228 - val_accuracy: 0.6875\n",
      "Epoch 24/28\n",
      "7/7 - 0s - loss: 1.2502 - accuracy: 0.8125 - val_loss: 1.2751 - val_accuracy: 0.6875\n",
      "Epoch 25/28\n",
      "7/7 - 0s - loss: 1.1990 - accuracy: 0.8438 - val_loss: 1.2144 - val_accuracy: 0.6875\n",
      "Epoch 26/28\n",
      "7/7 - 0s - loss: 1.1428 - accuracy: 0.8438 - val_loss: 1.1348 - val_accuracy: 0.6875\n",
      "Epoch 27/28\n",
      "7/7 - 0s - loss: 1.0732 - accuracy: 0.8594 - val_loss: 1.0287 - val_accuracy: 0.8125\n",
      "Epoch 28/28\n",
      "7/7 - 0s - loss: 0.9854 - accuracy: 0.9219 - val_loss: 0.8668 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e305bee20>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_samples, y=train_labels, validation_split=0.2, batch_size=10, epochs=28, shuffle=True, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
